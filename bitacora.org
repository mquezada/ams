* 7 nov 2016

- Pasos a seguir:
  - Elegir baselines
  - Escribir motivación del problema
  - Implementar baselines
  - Decidir ground truth(s)
  - Decidir forma(s) de evaluar
  - Evaluar!

- Indicar en la motivación que el trabajo relacionado no cumple todos nuestros requisitos.
- Por qué algunas técnicas no son suficientes para resolver el problema.

* 10 nov 2016

- Clasificar los papers por otros criterios:
  - Mencionan (y cuales) criterios de calidad de resumen
  - Consideran aspecto multimedia (no solo texto)
- Leer paper de Teresa para ver evaluacion


* 17 nov 2016
- Cuales son los mejores atributos que permiten generar resumenes
- Combinar los mejores features de alguna forma (aprenderlos) para generar los resumenes
- Baselines:
  - Random
  - Frequency
  - Learning to rank: estos son los datos, estos son los resumenes (gold-standard): “aprende de los datos”
- Implementar los baselines y diseñar el experimento
- … con eso diseñar la solucion propuesta y experimentar “en grande”
- Hablar con la Vanessa sobre el experimento para separar los atributos y medir sus aportes individuales?

* 18 nov 2016
- TODOs Baselines:
  - Implementar preprocesamiento de texto
  - Tratar con la no-redundancia
  - Considerar documentos en vez de tweets?
  - Leer e implementar? La metodologia de TweetMotif
  - Mirar los baselines que sean mas directos de implementar y que calcen muy bien con nuestros objetivos:
  - Hacer resumenes de (seleccionar) tweets O de documentos que son apuntados por los tweets

* 29 dic 2016
** Ideas para continuar
   1. aumentar tweets con palabras del word2vec, y usar tf-idf para modelar tweets/documentos
   2. representar tweets/documentos como promedio de vectores de las palabras en w2v
   3. lo mismo que 2, más aumentar tweets con palabras del w2v
   4. usar doc2vec para representar tweets/docs
   5. hacer grafo del evento usando w2v del evento + POS
   6. lo mismo que 5, usando w2v del corpus
* 5 ene 2017
** Semana anterior
   - doc2vec o word2vec en el mismo evento no funciona bien (pocos datos)
   - mgraph funcionando!
** Eliminar ruido de eventos
*** Experimento
   1. agrupar tweets por URL (= documento)
      - tweets sin URL son el documento correspondiente al mismo tweet
   2. aumentar documentos usando palabras mas similares en w2v general
   3. aplicar tf-idf
   4. hacer clustering (k-means)
*** Evaluacion
    - propiedades estructurales del clustering
      - SSE
      - diametro
      - silhouette
      - distancia intercluster
        - min
        - max
        - avg (centroide)
*** Parametros
    - Umbral de similitud W2V
      - umbral fijo
      - umbral fijo + codo (2da derivada)
    - numero de clusters en kmeans
    - distancia euclidiana o disimilitud coseno
    - eliminar tweets duplicados
    
* 6 ene 2017
  - mirar localized pagerank?
  - elegir un evento, y graficar en 2D las palabras + palabras mas cercanas usando modelo completo
   
* 17 ene 2017

- find fake news?
- classify events by topic using WE analogies
- removing noise (spam) from tweets
- MMR

- muc (message undestanding conf), tdt, trec 
- explainability of neural networks
- analogous events
- generating summaries
- finding sub-topics
- data cleaning/curation/detection
- applying structure to a bag of tweets
- user weight on credibility

* 24 mar 2017
- Diseñar la medida de distancia
- Implementar o buscar un clustering que use esta medida
- Diseñar interfaz para ver los resultados

* 31 mar 2017
- LM: charla de tesis I

* 18 abr 2017
- MQ: presentación de examen de propuesta

* 24 abr 2017
** Avance
- definicion modelo: https://github.com/mquezada/ams/blob/clustering/tex/model.pdf

* 28 abr 2017
** Avance
- Se agregaron referencias de Social Anchor Text y Multimodal summarization: https://docs.google.com/spreadsheets/d/1TZadD1nYuPd6N6qogtkGdmoqBhWQy4RF2wkoVCt2qKc/edit#gid=175296704

* 5 may 2017
** Avance
- es difícil inspeccionar los clusters debido a la alta redundancia de los datos (muchos tweets repetidos)
- se probó con TwitterLDA y clustering jerárquico
- se quedó en usar sólo un representante por documento

* 9 may 2017
** Avance
- documentos ahora estan representados por 1 tweet:
  - si varios tweets retuitean a un tweet, éste último es el representante
  - si varios tweets comparten una url u, cualquiera de éstos es el representante
- Los resultados de hacer clustering con kmeans (mini batch kmeans) mejoran con respecto a la representacion anterior (1 documento = todos los tweets, o los tweets individuales), sin embargo, clusters contienen overlap de topicos al mirar evento libya_hotel
- Al usar CLUTO con clustering aglomerativo, los resultados se ven mucho mejor un par de eventos inspeccionados (oscar_pistorius y libya_hotel). Con un evento no es fácil decir cómo son los clusters (microsoft_nokia).

** Queda por definir
1. determinar número de clusters apropiados (fijo o variable)
2. elegir representantes por cluster
3. aplicaciones o formas de evaluar el clustering / resumen

** Trabajo para la próxima reunión
- Fijar número de clusters de forma manual y probar distintas formas de clustering
  - idea: elegir el clustering con un numero fijo de clusters para facilitar la eleccion del clustering. Despues nos preocupamos de (1)
- Elegir representantes por cluster de manera naive / simple
  - ejemplo: numero de tweets asociados al cluster, numero de rts, favs, replies
- Pensar en (3)
  - ejemplo: comparar con pagina en wikipedia, o considerar otro ground truth (reportaje en cnn, bbc, etc)
  - al mirar wikipedia, comparar el overlap de topicos de wikipedia vs nuestro resumen y ver si es posible sugerir edits 
  - metadata de eventos para exploracion (galean?)